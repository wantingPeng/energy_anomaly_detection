# Configuration file for Random Forest time series anomaly detection

# Paths
paths:
  output_dir: "experiments/random_forest"

# Data configuration
data:
  # Path to processed window features
  data_path: "Data/downsampleData_scratch_1minut/contact/contact_cleaned_1minut_20250928_172122.parquet"
  
  # Train/validation/test split ratios
  train_ratio: 0.7
  val_ratio: 0.15
  test_ratio: 0.15
  
  # Target column
  target_column: "anomaly_label"
  
  # Columns to exclude from features
  exclude_columns:
    - "TimeStamp"
    - "window_id"
    - "anomaly_label"
  
  # Method to balance classes (None or 'class_weight')
  # 'class_weight' uses scikit-learn's class_weight='balanced' option
  balance_method: "class_weight"

# Model configuration
model:
  # Number of trees in the forest
  n_estimators: 100
  
  # Maximum depth of the tree
  # None means unlimited
  max_depth: 6
  
  # Minimum number of samples required to split an internal node
  min_samples_split: 20
  
  # Minimum number of samples required to be at a leaf node
  min_samples_leaf: 20
  
  # Number of features to consider for best split
  # 'sqrt': sqrt(n_features)
  # 'log2': log2(n_features)
  # float: fraction of features
  # int: absolute number of features
  max_features: 0.3
  #max_samples: 0.7 
  # Whether to use bootstrap samples
  bootstrap: true
  
  # Whether to use out-of-bag samples to estimate generalization score
  oob_score: true
  
  # Class weights (auto computed if data.balance_method = 'class_weight')
  class_weight: balanced
  
  # Number of parallel jobs
  # -1 means use all processors
  n_jobs: -1
  
  # Random state for reproducibility
  random_state: 42
  
  # Verbosity level
  verbose: 1

# Training configuration
training:
  # Whether to optimize decision threshold
  optimize_threshold: true
  
  # Metric to optimize threshold for
  # Options: f1, precision, recall
  threshold_metric: "f1"

# Evaluation configuration
evaluation:
  # Whether to use point adjustment
  use_point_adjustment: true
  
  # Whether to save predictions
  save_predictions: true
  
  # Whether to plot precision-recall and ROC curves
  plot_curves: true

# Feature importance
feature_importance:
  # Whether to save feature importance
  save_importance: true
  
  # Type of feature importance to compute
  # Options: impurity (default), permutation (needs validation data)
  importance_type: "impurity"
  
  # Number of top features to plot
  plot_top_n: 30
