# FEDformer 分钟级能源异常检测配置
# 主训练脚本: src/training/fedformer/train_fedformer.py

# 数据配置
data:
  data_dir: "Data/row_energyData_subsample_Transform/labeled"
  component: "contact"
  freq: "t"  # 分钟级频率 (minute)
  
  # 分钟级数据的序列配置
  seq_len: 1440      # 24小时输入窗口 (24*60=1440分钟)
  label_len: 720     # 12小时标签窗口 (12*60=720分钟)  
  pred_len: 360      # 6小时预测窗口 (6*60=360分钟)
  
  # 数据处理
  exclude_columns: ["TimeStamp", "segment_id", "ID"]
  time_embed: "timeF"  # 时间特征嵌入
  step_size: 1
  
  # 数据分割
  validation_split: 0.2
  test_split: 0.1
  max_train_samples: 500000  # 限制训练样本数量（分钟级数据量大）

# 模型架构配置
model:
  # 基础架构
  d_model: 256        # 模型维度（针对分钟级数据优化）
  n_heads: 8          # 注意力头数
  e_layers: 2         # 编码器层数（减少以控制复杂度）
  d_layers: 1         # 解码器层数
  d_ff: 1024          # 前馈网络维度
  dropout: 0.1        # Dropout率
  activation: "gelu"  # 激活函数
  
  # FEDformer 特有参数
  modes: 64           # 傅里叶模式数（增加以捕获多种周期）
  mode_select: "random"  # 模式选择策略
  version: "Fourier"     # 版本：Fourier 或 Wavelets
  moving_avg: 25         # 移动平均核大小
  L: 1                   # 频率增强层数
  base: "legendre"       # 分解基础
  cross_activation: "tanh"  # 交叉注意力激活
  
  # 时间嵌入
  embed: "timeF"      # 时间特征嵌入类型
  
  # 异常检测配置
  num_classes: 2      # 二分类异常检测
  output_attention: false  # 是否输出注意力权重

# 训练配置
training:
  # 基础训练参数
  batch_size: 8       # 小批量大小（长序列内存考虑）
  learning_rate: 0.0001
  weight_decay: 0.0001
  max_epochs: 50
  patience: 10        # 早停耐心
  
  # 内存优化
  gradient_accumulation_steps: 4  # 梯度累积（有效更大批量）
  mixed_precision: true           # 混合精度训练
  
  # 损失函数
  loss_type: "focal"    # focal, cross_entropy, weighted_ce
  focal_alpha: 1.0      # Focal Loss alpha
  focal_gamma: 2.0      # Focal Loss gamma
  class_weights: null   # 类别权重，null为自动计算
  
  # 学习率调度
  scheduler: "plateau"  # plateau, cosine, step
  scheduler_patience: 5
  scheduler_factor: 0.5
  
  # 验证配置
  val_check_interval: 1  # 每几个epoch验证一次
  save_top_k: 3         # 保存最好的k个模型

# 关键周期配置（分钟为单位）
periodicity:
  key_periods:
    - 60      # 1小时
    - 180     # 3小时  
    - 360     # 6小时
    - 720     # 12小时
    - 1440    # 24小时（日周期）
    - 2880    # 48小时
    - 4320    # 72小时（3天）
    - 10080   # 168小时（周周期）
  
  seasonal_periods:
    - 1440    # 日季节性（24小时）
    - 10080   # 周季节性（168小时）

# 实验配置
experiment:
  name: "fedformer_minute_anomaly"
  version: "v1.0"
  description: "FEDformer用于分钟级能源异常检测"
  
  # 日志和保存
  log_dir: "experiments/logs"
  model_save_dir: "experiments/fedformer_anomaly"
  tensorboard_dir: "experiments/tensorboard"
  
  # 随机种子
  seed: 42
  
  # 设备配置
  gpu_id: 0
  num_workers: 4

# 预设配置模式
config_mode: "standard"  # standard, memory, weekly

# 内存受限模式配置
memory_mode:
  model:
    d_model: 128
    modes: 32
    e_layers: 1
  data:
    seq_len: 720       # 12小时
    label_len: 360     # 6小时
    pred_len: 180      # 3小时
  training:
    batch_size: 4
    gradient_accumulation_steps: 8

# 周模式配置（捕获长期模式）
weekly_mode:
  data:
    seq_len: 2160      # 36小时（1.5天）
    label_len: 1440    # 24小时
    pred_len: 720      # 12小时
  model:
    modes: 96          # 更多模式捕获复杂模式
  training:
    batch_size: 4      # 更小批量 